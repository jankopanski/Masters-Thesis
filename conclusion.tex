\documentclass[thesis-en.tex]{subfiles}

\begin{document}
The ever increasing gap between compute and I/O performance in supercomputing platforms together with the development in persistence storage led to the idea of burst buffers---a fast persistence storage layer logically positioned between the random access main memory and parallel file system. Since the appearance of this concept, numerous supercomputers have been equipped with burst buffers exploiting various architectures such as compute-node--local burst buffers or remote shared burst buffers co-located with I/O nodes. In majority of cases, the novel NVMe Solid State Drives were selected as hardware implementation of the persistent storage. This new kind of technology sparked a novel branch in HPC research, which already brought several prominent publications on improving the software side of burst buffer capabilities.

Despite the development of real-world architectures as well as research concepts, Resource and Job Management Systems provide only marginal support for burst buffer utilisation. They usually allow to specify burst buffer allocation by users, but do not include storage reservations in backfilling during job scheduling. We presumed that this scheduling behaviour could potentially cause significant efficiency deterioration. That is the primary observation that motivated our research.

In this dissertation, we presented a detailed overview of burst buffer technology and online job scheduling concepts. Due to a lack of publicly available trace logs, we forged our workload with burst buffer requests based on analysis of main memory requests in logs from the Parallel Workloads Archive. We created two simulation models: one which performs job scheduling and simulates resource allocations and the other that extends it with I/O contention and I/O congestion effects. We proposed three new algorithms focused on improving scheduling performance by burst buffer awareness. Finally, we performed numerous experiments which led to several conclusions.

\begin{enumerate}
    \item The lack of future burst buffer reservations in EASY-backfilling may drastically deteriorate the efficiency of job scheduling. In our simulations, we observed that backfilling without future burst buffer reservations resulted in mean waiting time comparable or even worse than First-Come-First-Served without any backfilling. Furthermore, backfilling future burst buffer reservations presented significantly more extensive distribution of job waiting times with a large number of outliers.
    \item We also observed that the lack of future burst buffer reservations in EASY-backfilling could lead to starvation of medium-size and wide jobs. This situation happens when a wide job at the front of the waiting queue is selected for a future reservation in backfilling. This job needs to request not only a large number of processors but almost all available burst buffer capacity in a platform. Then, narrow-short jobs behind it could be backfilled at the front if only there are enough compute resource. Moreover, in online scheduling with a constant stream of submitted narrow-short jobs, the wide jobs can be almost arbitrary delayed.
    \item Plan-based scheduling algorithms showed superior performance in burst-buffer--aware online job scheduling. The best plan-based algorithms improved the mean waiting time by $20\%$ and mean bounded slowdown by $27\%$ compared to Shortest-Jobs-First EASY-backfilling. Plan-based scheduling algorithms proved to be universally better in terms of summary statistics for all studied metrics. Their only downside is a slightly larger number of outliers compared to canonical backfilling algorithms. Furthermore, they are resource agnostic, that is they could be easily generalised to multi-resource scheduling for any kinds of resources. Plan-based scheduling algorithms are also agnostic from resource allocation techniques as they are based on optimising the order of jobs taken to scheduling.
    \item The optimal value of the backfilling reservation depth is $1$ for the canonical First-Come-First-Served and Shortest-Jobs-First backfilling. For all values above $1$, we observed a monotonic decrease of scheduling efficiency in all investigated metrics. Removing resource reservations from backfilling deteriorates the performance as well by arbitrary delaying some jobs.
    \item Mean is not a representative statistic for online job scheduling. We presented our results based on four metrics: waiting time, turnaround time, slowdown and bounded slowdown. For those metrics, we used different visualisation techniques such as mean, unaggregated values for a tail of distribution and boxenplots, which shows several ordered statistics. We observed that two schedules with almost identical mean may have completely different distributions.
    \item The addition of I/O congestion and I/O contention effects did not significantly change the results of job scheduling compared to the simulation with resource allocations only. The only exception from this observation applied to Shortest-Jobs-First EASY-backfilling.
\end{enumerate}
\end{document}